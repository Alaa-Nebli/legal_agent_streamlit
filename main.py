"""
Enhanced Human-like Legal Expert Chat Application
Streamlit-based chat interface with natural conversation flow
"""

import os
import json
import streamlit as st
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import time
import re

# Lang/OpenAI/Pinecone imports
from langchain.agents import tool
from langchain_core.runnables import Runnable
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone

# Configure Streamlit page
st.set_page_config(
    page_title="üèõÔ∏è Ma√Ætre Khalil - Expert Juridique",
    page_icon="‚öñÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for a more professional, human-like interface
st.markdown("""
<style>
    .chat-message {
        padding: 1.2rem; 
        border-radius: 1rem; 
        margin-bottom: 1rem; 
        display: flex;
        flex-direction: column;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .chat-message.user {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        margin-left: 15%;
        border-bottom-right-radius: 0.3rem;
    }
    .chat-message.assistant {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
        margin-right: 15%;
        border-bottom-left-radius: 0.3rem;
    }
    .expert-name {
        font-weight: bold;
        font-size: 1.1em;
        margin-bottom: 0.5rem;
        opacity: 0.9;
    }
    .thinking-indicator {
        font-style: italic;
        opacity: 0.7;
        font-size: 0.9em;
    }
    .source-citation {
        background: rgba(255,255,255,0.2);
        padding: 0.8rem;
        border-left: 4px solid #fff;
        margin: 1rem 0;
        border-radius: 0.5rem;
        backdrop-filter: blur(10px);
    }
    .legal-reference {
        background: rgba(255,255,255,0.15);
        padding: 0.5rem;
        border-radius: 0.3rem;
        margin: 0.3rem 0;
        font-family: 'Courier New', monospace;
        font-size: 0.9em;
    }
</style>
""", unsafe_allow_html=True)

# --- Configuration ---
@st.cache_resource
def initialize_connections():
    """Initialize all connections with caching for better performance"""
    
    try:
        OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
        PINECONE_API_KEY = st.secrets["PINECONE_API_KEY"]
    except:
        OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
        PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "")


    if not OPENAI_API_KEY or not PINECONE_API_KEY:
        st.error("‚ö†Ô∏è Les cl√©s API ne sont pas configur√©es. Veuillez d√©finir OPENAI_API_KEY et PINECONE_API_KEY.")
        st.stop()
    
    # Configuration
    PINECONE_ENV = "us-east-1"
    PINECONE_INDEX = "tunisia-laws"
    
    # Models for different purposes
    CHAT_MODEL = "gpt-4o"  # For natural conversation
    ANALYSIS_MODEL = "gpt-4o"  # For deep legal analysis
    RERANK_MODEL = "gpt-4o-mini"  # For document ranking
    EMBEDDING_MODEL_NAME = "text-embedding-ada-002"
    
    # Initialize connections
    pc = Pinecone(api_key=PINECONE_API_KEY)
    index = pc.Index(PINECONE_INDEX)
    
    embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY, model=EMBEDDING_MODEL_NAME)
    
    # Fix: Create custom vector store that handles the content field correctly
    class TunisianLegalVectorStore(PineconeVectorStore):

        def similarity_search_with_score(self, query: str, k: int = 4, filter: Optional[dict] = None, **kwargs) -> List[Tuple]:
            """Override to handle our document structure"""
            results = []
            try:
                # Query Pinecone directly
                query_vector = self._embedding.embed_query(query)
                pinecone_results = self._index.query(
                    vector=query_vector,
                    top_k=k,
                    include_metadata=True,
                    filter=filter
                )
                
                for match in pinecone_results.matches:
                    metadata = match.metadata
                    
                    # Extract content based on available fields
                    content = ""
                    if 'content_fr' in metadata and metadata['content_fr']:
                        content = metadata['content_fr']
                    elif 'content_ar' in metadata and metadata['content_ar']:
                        content = metadata['content_ar']
                    elif 'summary' in metadata:
                        content = metadata['summary']
                    else:
                        continue  # Skip if no content found
                    
                    # Create document-like object
                    doc = type('Document', (), {
                        'page_content': content,
                        'metadata': metadata
                    })()
                    
                    results.append((doc, match.score))
                    
            except Exception as e:
                st.error(f"Erreur lors de la recherche: {e}")
                
            return results
        
        def similarity_search(self, query: str, k: int = 4, filter: Optional[dict] = None, **kwargs):
            """Override similarity_search to use our custom method"""
            docs_and_scores = self.similarity_search_with_score(query, k=k, filter=filter, **kwargs)
            return [doc for doc, score in docs_and_scores]
    
    vector_store = TunisianLegalVectorStore(index=index, embedding=embeddings, text_key="content")
    
    # LLM clients
    llm_chat = ChatOpenAI(api_key=OPENAI_API_KEY, model=CHAT_MODEL, temperature=0.7)
    llm_analysis = ChatOpenAI(api_key=OPENAI_API_KEY, model=ANALYSIS_MODEL, temperature=0.3)
    llm_rerank = ChatOpenAI(api_key=OPENAI_API_KEY, model=RERANK_MODEL, temperature=0)
    
    return {
        "vector_store": vector_store,
        "llm_chat": llm_chat,
        "llm_analysis": llm_analysis,
        "llm_rerank": llm_rerank,
        "index": index
    }

# Initialize connections
connections = initialize_connections()
vector_store = connections["vector_store"]
llm_chat = connections["llm_chat"]
llm_analysis = connections["llm_analysis"]
llm_rerank = connections["llm_rerank"]

# --- Enhanced Data Classes ---
@dataclass
class LegalDocument:
    id: str
    title: str
    article_number: int
    content_fr: str
    content_ar: str
    legal_code: str
    summary: str
    tags: List[str]
    status: str
    relevance_score: float = 0.0
    
@dataclass
class ConversationContext:
    user_question: str
    detected_language: str
    legal_domain: str
    complexity_level: str
    follow_up_questions: List[str]

# --- Human-like Legal Expert Class ---
class MaitreKhalil:
    def __init__(self):
        self.name = "Ma√Ætre Khalil Ben Ahmed"
        self.specialties = [
            "Droit commercial tunisien",
            "Droit civil et obligations",
            "Droit p√©nal des affaires",
            "Comptabilit√© publique",
            "Proc√©dures juridiques"
        ]
        self.vector_store = vector_store
        self.llm_chat = llm_chat
        self.llm_analysis = llm_analysis
        self.llm_rerank = llm_rerank
        
    def _detect_language_and_context(self, query: str) -> ConversationContext:
        """Analyze the query to understand context and user needs"""
        
        # Simple language detection
        arabic_chars = len(re.findall(r'[\u0600-\u06FF]', query))
        total_chars = len(query.replace(' ', ''))
        detected_language = "ar" if arabic_chars > total_chars * 0.3 else "fr"
        
        # Detect legal domain based on keywords
        domain_keywords = {
            "commercial": ["commerce", "entreprise", "soci√©t√©", "contrat commercial", "ÿ™ÿ¨ÿßÿ±ÿ©", "ÿ¥ÿ±ŸÉÿ©"],
            "civil": ["mariage", "divorce", "succession", "propri√©t√©", "ÿ≤Ÿàÿßÿ¨", "ÿ∑ŸÑÿßŸÇ", "ŸÖŸäÿ±ÿßÿ´"],
            "penal": ["crime", "d√©lit", "sanction", "prison", "ÿ¨ÿ±ŸäŸÖÿ©", "ÿπŸÇŸàÿ®ÿ©"],
            "public": ["administration", "finances publiques", "comptabilit√©", "ÿ•ÿØÿßÿ±ÿ©", "ŸÖÿßŸÑŸäÿ© ÿπÿßŸÖÿ©"],
            "procedure": ["proc√©dure", "tribunal", "recours", "ÿ•ÿ¨ÿ±ÿßÿ°ÿßÿ™", "ŸÖÿ≠ŸÉŸÖÿ©"]
        }
        
        legal_domain = "general"
        for domain, keywords in domain_keywords.items():
            if any(keyword.lower() in query.lower() for keyword in keywords):
                legal_domain = domain
                break
        
        # Assess complexity
        complexity_indicators = ["exception", "recours", "cassation", "constitutionnel", "ÿßÿ≥ÿ™ÿ´ŸÜÿßÿ°", "ÿ∑ÿπŸÜ"]
        complexity_level = "complex" if any(ind.lower() in query.lower() for ind in complexity_indicators) else "standard"
        
        return ConversationContext(
            user_question=query,
            detected_language=detected_language,
            legal_domain=legal_domain,
            complexity_level=complexity_level,
            follow_up_questions=[]
        )
    
    def _search_legal_documents(self, query: str, legal_code: Optional[str] = None, top_k: int = 15) -> List[LegalDocument]:
        """Search for relevant legal documents"""
        
        try:
            # Build filter
            filter_dict = {}
            if legal_code and legal_code != "all":
                filter_dict["legal_code"] = {"$eq": legal_code}
            
            # Search with our custom vector store
            docs_with_scores = vector_store.similarity_search_with_score(
                query, 
                k=top_k, 
                filter=filter_dict
            )
            
            legal_docs = []
            for doc, score in docs_with_scores:
                metadata = doc.metadata
                
                legal_doc = LegalDocument(
                    id=metadata.get("id", "unknown"),
                    title=metadata.get("title", "Document sans titre"),
                    article_number=metadata.get("article_index", 0),
                    content_fr=metadata.get("content_fr", ""),
                    content_ar=metadata.get("content_ar", ""),
                    legal_code=metadata.get("legal_code", ""),
                    summary=metadata.get("summary", ""),
                    tags=metadata.get("tags", []),
                    status=metadata.get("status", ""),
                    relevance_score=float(score)
                )
                legal_docs.append(legal_doc)
            
            return legal_docs
            
        except Exception as e:
            st.error(f"Erreur lors de la recherche: {e}")
            return []
    
    def _rerank_documents(self, context: ConversationContext, documents: List[LegalDocument]) -> List[LegalDocument]:
        """Intelligently rerank documents based on context"""
        
        if not documents:
            return []
        
        # Prepare documents for ranking
        docs_for_ranking = []
        for doc in documents:
            content = doc.content_fr if context.detected_language == "fr" else doc.content_ar
            if not content:  # Fallback to the other language
                content = doc.content_ar if context.detected_language == "fr" else doc.content_fr
            
            docs_for_ranking.append({
                "id": doc.id,
                "title": doc.title,
                "article_number": doc.article_number,
                "legal_code": doc.legal_code,
                "content": content[:800],  # Truncate for ranking
                "summary": doc.summary,
                "tags": doc.tags
            })
        
        rerank_prompt = f"""En tant qu'expert juridique tunisien, √©valuez la pertinence de chaque document pour cette question:

Question: {context.user_question}
Domaine juridique d√©tect√©: {context.legal_domain}
Niveau de complexit√©: {context.complexity_level}

Documents √† √©valuer:
{json.dumps(docs_for_ranking, ensure_ascii=False, indent=2)}

Donnez un score de pertinence (0-100) pour chaque document. Consid√©rez:
- Pertinence directe au probl√®me juridique
- Applicabilit√© en droit tunisien
- Niveau de d√©tail appropri√©

R√©pondez uniquement en JSON:
{{"rankings": [{{"id": "...", "score": 0-100, "rationale": "..."}}]}}"""

        try:
            response = self.llm_rerank.invoke([{"role": "user", "content": rerank_prompt}])
            rankings_data = json.loads(response.content.strip())
            
            # Apply new scores
            id_to_score = {r["id"]: r["score"] for r in rankings_data.get("rankings", [])}
            for doc in documents:
                doc.relevance_score = id_to_score.get(doc.id, doc.relevance_score)
            
            # Sort by new relevance score
            return sorted(documents, key=lambda x: x.relevance_score, reverse=True)[:5]
            
        except Exception as e:
            st.warning(f"Probl√®me avec le re-classement: {e}")
            return documents[:5]
    
    def _generate_human_response(self, context: ConversationContext, relevant_docs: List[LegalDocument]) -> str:
        """Generate a natural, human-like response"""
        
        if not relevant_docs:
            return self._generate_no_results_response(context)
        
        # Prepare legal context
        legal_context = []
        for doc in relevant_docs:
            content = doc.content_fr if context.detected_language == "fr" else doc.content_ar
            if not content:
                content = doc.content_ar if context.detected_language == "fr" else doc.content_fr
            
            legal_context.append({
                "article": doc.article_number,
                "title": doc.title,
                "code": doc.legal_code,
                "content": content,
                "summary": doc.summary,
                "status": doc.status,
                "relevance": doc.relevance_score
            })
        
        # Create human-like persona prompt
        persona_prompt = f"""Vous √™tes Ma√Ætre Khalil Ben Ahmed, un avocat tunisien exp√©riment√© avec 20 ans d'exp√©rience.

VOTRE PERSONNALIT√â:
- Chaleureux et accessible, mais professionnel
- Vous expliquez le droit de mani√®re claire et p√©dagogique
- Vous utilisez des exemples concrets
- Vous √™tes prudent et mentionnez quand consulter un avocat
- Vous ma√Ætrisez parfaitement le fran√ßais et l'arabe
- Vous avez une connaissance approfondie du droit tunisien

STYLE DE COMMUNICATION:
- Commencez par une salutation personnelle
- Structurez votre r√©ponse clairement
- Utilisez "En droit tunisien..." ou "Selon la l√©gislation..."
- Terminez par des conseils pratiques
- Soyez empathique aux pr√©occupations du client

QUESTION DU CLIENT: {context.user_question}

CONTEXTE JURIDIQUE PERTINENT:
{json.dumps(legal_context, ensure_ascii=False, indent=2)}

R√©pondez comme un vrai avocat tunisien le ferait lors d'une consultation. Soyez naturel, professionnel et rassurant."""

        try:
            response = self.llm_chat.invoke([{"role": "user", "content": persona_prompt}])
            base_response = response.content.strip()
            
            # Add legal references in a natural way
            if relevant_docs:
                base_response += "\n\nüìã **R√©f√©rences juridiques consult√©es:**\n"
                for i, doc in enumerate(relevant_docs[:3], 1):
                    base_response += f"{i}. Article {doc.article_number} - {doc.title} ({doc.legal_code})\n"
                    if doc.status:
                        base_response += f"   *{doc.status}*\n"
            
            return base_response
            
        except Exception as e:
            return f"Je suis d√©sol√©, j'ai rencontr√© un probl√®me technique. Pouvez-vous reformuler votre question ? (Erreur: {e})"
    
    def _generate_no_results_response(self, context: ConversationContext) -> str:
        """Generate a helpful response when no relevant documents are found"""
        
        responses = [
            f"Je comprends votre question sur {context.legal_domain}, mais je n'ai pas trouv√© de textes juridiques sp√©cifiques dans ma base de donn√©es actuelle.",
            "Permettez-moi de vous orienter diff√©remment. Pouvez-vous me donner plus de d√©tails sur votre situation ?",
            "En attendant, je vous recommande de consulter directement un confr√®re sp√©cialis√© pour une analyse personnalis√©e."
        ]
        
        if context.legal_domain != "general":
            responses.append(f"Pour les questions de {context.legal_domain}, il serait peut-√™tre utile de consulter directement le code concern√©.")
        
        return "\n\n".join(responses)
    
    def respond_to_question(self, user_input: str, legal_code_filter: Optional[str] = None) -> Tuple[str, Dict]:
        """Main method to process user question and generate response"""
        
        # Analyze context
        context = self._detect_language_and_context(user_input)
        
        # Search for relevant documents
        documents = self._search_legal_documents(
            user_input, 
            legal_code=legal_code_filter,
            top_k=15
        )
        
        # Rerank based on context
        relevant_docs = self._rerank_documents(context, documents)
        
        # Generate human-like response
        response = self._generate_human_response(context, relevant_docs)
        
        # Prepare metadata for UI
        metadata = {
            "detected_language": context.detected_language,
            "legal_domain": context.legal_domain,
            "documents_found": len(documents),
            "documents_used": len(relevant_docs),
            "complexity": context.complexity_level
        }
        
        return response, metadata

# --- Streamlit Interface ---
def main():
    # Header with expert introduction
    st.markdown("""
    <div style='text-align: center; padding: 2rem 0;'>
        <h1>üèõÔ∏è Ma√Ætre Khalil Ben Ahmed</h1>
        <h3 style='color: #666; font-weight: normal;'>Avocat & Expert en Droit Tunisien</h3>
        <p style='font-style: italic; color: #888;'>Sp√©cialis√© en droit commercial, civil et comptabilit√© publique</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar with expert profile
    with st.sidebar:
        st.markdown("""
        ### üë®‚Äç‚öñÔ∏è Profil de l'Expert
        
        **Ma√Ætre Khalil Ben Ahmed**
        - üéì 20+ ans d'exp√©rience
        - üèõÔ∏è Droit tunisien
        - üìö Sp√©cialit√©s multiples
        - üåê Bilingue FR/AR
        
        ---
        """)
        
        # Legal code filter
        st.subheader("üîç Filtrer par domaine")
        legal_codes = {
            "Tous les domaines": None,
            "üìä Comptabilit√© publique": "code-comptabilite-publique",
            "üè¢ Droit commercial": "code-commerce",
            "üë• Droit civil": "code-civil",
            "‚öñÔ∏è Droit p√©nal": "code-penal",
            "üíº Droit du travail": "code-travail",
            "üìã Proc√©dure civile": "code-procedure-civile"
        }
        
        selected_code_display = st.selectbox(
            "Domaine juridique",
            list(legal_codes.keys()),
            help="Concentrer la recherche sur un domaine sp√©cifique"
        )
        selected_code = legal_codes[selected_code_display]
        
        # Expert availability status
        st.markdown("""
        ---
        ### üìä Statut
        üü¢ **En ligne** - R√©ponse imm√©diate  
        üìñ Base juridique √† jour  
        üîí Consultations confidentielles
        """)
        
        # Quick tips
        with st.expander("üí° Conseils pour de meilleures r√©ponses"):
            st.markdown("""
            - Soyez sp√©cifique dans vos questions
            - Mentionnez le contexte (personnel/entreprise)
            - Pr√©cisez si c'est urgent
            - N'h√©sitez pas √† demander des clarifications
            """)
    
    # Initialize chat
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # Add welcome message
        welcome_msg = """Bonjour ! Je suis Ma√Ætre Khalil Ben Ahmed, avocat sp√©cialis√© en droit tunisien.

Je suis l√† pour vous aider avec vos questions juridiques, que ce soit en droit commercial, civil, p√©nal, ou comptabilit√© publique. 

N'h√©sitez pas √† me poser votre question en fran√ßais ou en arabe. Je vous donnerai une r√©ponse claire avec les r√©f√©rences juridiques appropri√©es.

Comment puis-je vous aider aujourd'hui ? üòä"""
        
        st.session_state.messages.append({
            "role": "assistant", 
            "content": welcome_msg,
            "metadata": {}
        })
    
    if "expert" not in st.session_state:
        st.session_state.expert = MaitreKhalil()
    
    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant":
                st.markdown(f'<div class="expert-name">üë®‚Äç‚öñÔ∏è Ma√Ætre Khalil</div>', unsafe_allow_html=True)
            
            st.markdown(message["content"])
            
            # Show metadata for assistant messages (except welcome)
            if (message["role"] == "assistant" and 
                message.get("metadata") and 
                len(message["metadata"]) > 0):
                
                meta = message["metadata"]
                with st.expander("üìä D√©tails de l'analyse", expanded=False):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üåê Langue d√©tect√©e", meta.get("detected_language", "fr").upper())
                    with col2:
                        st.metric("‚öñÔ∏è Domaine", meta.get("legal_domain", "general"))
                    with col3:
                        st.metric("üìÑ Documents analys√©s", f"{meta.get('documents_used', 0)}/{meta.get('documents_found', 0)}")
    
    # Chat input
    if prompt := st.chat_input("Tapez votre question juridique..."):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt, "metadata": {}})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Generate expert response
        with st.chat_message("assistant"):
            st.markdown(f'<div class="expert-name">üë®‚Äç‚öñÔ∏è Ma√Ætre Khalil</div>', unsafe_allow_html=True)
            
            # Show thinking indicator
            thinking_placeholder = st.empty()
            thinking_placeholder.markdown('<div class="thinking-indicator">ü§î Analyse de votre question et recherche dans la jurisprudence...</div>', unsafe_allow_html=True)
            
            try:
                # Get response from expert
                response, metadata = st.session_state.expert.respond_to_question(
                    prompt, 
                    legal_code_filter=selected_code
                )
                
                # Clear thinking indicator and show response
                thinking_placeholder.empty()
                st.markdown(response)
                
                # Store the response
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "metadata": metadata
                })
                
                # Show analysis details
                if metadata:
                    with st.expander("üìä D√©tails de l'analyse", expanded=False):
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("üåê Langue d√©tect√©e", metadata.get("detected_language", "fr").upper())
                        with col2:
                            st.metric("‚öñÔ∏è Domaine", metadata.get("legal_domain", "general"))
                        with col3:
                            st.metric("üìÑ Documents analys√©s", f"{metadata.get('documents_used', 0)}/{metadata.get('documents_found', 0)}")
                
            except Exception as e:
                thinking_placeholder.empty()
                error_msg = f"Je suis d√©sol√©, j'ai rencontr√© un probl√®me technique. Pouvez-vous r√©essayer ? üîß\n\nD√©tails: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": error_msg,
                    "metadata": {}
                })
    
    # Footer
    st.markdown("---")
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        st.markdown("""
        <div style='font-size: 0.8em; color: #666;'>
        ‚ö†Ô∏è <strong>Avertissement:</strong> Ces r√©ponses sont √† titre informatif uniquement. 
        Pour des conseils juridiques personnalis√©s, consultez un avocat.
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        if st.button("üîÑ Nouvelle consultation"):
            st.session_state.messages = []
            st.rerun()
    
    with col3:
        if st.button("üìû Contact direct"):
            st.info("üìß khalil.ahmed@avocat.tn\nüì± +216 XX XXX XXX")

if __name__ == "__main__":
    main()