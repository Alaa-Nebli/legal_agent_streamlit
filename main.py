"""
Enhanced Human-like Legal Expert Chat Application
Streamlit-based chat interface with natural conversation flow
"""

import os
import json
import streamlit as st
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import time
import re

# Lang/OpenAI/Pinecone imports
from langchain.agents import tool
from langchain_core.runnables import Runnable
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone

# Configure Streamlit page
st.set_page_config(
    page_title="ğŸ›ï¸ MaÃ®tre Khalil - Expert Juridique",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for a more professional, human-like interface
st.markdown("""
<style>
    .chat-message {
        padding: 1.2rem; 
        border-radius: 1rem; 
        margin-bottom: 1rem; 
        display: flex;
        flex-direction: column;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .chat-message.user {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        margin-left: 15%;
        border-bottom-right-radius: 0.3rem;
    }
    .chat-message.assistant {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
        margin-right: 15%;
        border-bottom-left-radius: 0.3rem;
    }
    .expert-name {
        font-weight: bold;
        font-size: 1.1em;
        margin-bottom: 0.5rem;
        opacity: 0.9;
    }
    .thinking-indicator {
        font-style: italic;
        opacity: 0.7;
        font-size: 0.9em;
    }
    .source-citation {
        background: rgba(255,255,255,0.2);
        padding: 0.8rem;
        border-left: 4px solid #fff;
        margin: 1rem 0;
        border-radius: 0.5rem;
        backdrop-filter: blur(10px);
    }
    .legal-reference {
        background: rgba(255,255,255,0.15);
        padding: 0.5rem;
        border-radius: 0.3rem;
        margin: 0.3rem 0;
        font-family: 'Courier New', monospace;
        font-size: 0.9em;
    }
</style>
""", unsafe_allow_html=True)

# --- Configuration ---
@st.cache_resource
def initialize_connections():
    """Initialize all connections with caching for better performance"""
    
    try:
        OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
        PINECONE_API_KEY = st.secrets["PINECONE_API_KEY"]
    except:
        OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
        PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "")


    if not OPENAI_API_KEY or not PINECONE_API_KEY:
        st.error("âš ï¸ Les clÃ©s API ne sont pas configurÃ©es. Veuillez dÃ©finir OPENAI_API_KEY et PINECONE_API_KEY.")
        st.stop()
    
    # Configuration
    PINECONE_ENV = "us-east-1"
    PINECONE_INDEX = "tunisia-laws"
    
    # Models for different purposes
    CHAT_MODEL = "gpt-4o"  # For natural conversation
    ANALYSIS_MODEL = "gpt-4o"  # For deep legal analysis
    RERANK_MODEL = "gpt-4o-mini"  # For document ranking
    EMBEDDING_MODEL_NAME = "text-embedding-ada-002"
    
    # Initialize connections
    pc = Pinecone(api_key=PINECONE_API_KEY)
    index = pc.Index(PINECONE_INDEX)
    
    embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY, model=EMBEDDING_MODEL_NAME)
    
    # Fix: Create custom vector store that handles the content field correctly
    class TunisianLegalVectorStore(PineconeVectorStore):

        def similarity_search_with_score(self, query: str, k: int = 4, filter: Optional[dict] = None, **kwargs) -> List[Tuple]:
            """Override to handle our document structure"""
            results = []
            try:
                # Query Pinecone directly
                query_vector = self._embedding.embed_query(query)
                pinecone_results = self._index.query(
                    vector=query_vector,
                    top_k=k,
                    include_metadata=True,
                    filter=filter
                )
                
                for match in pinecone_results.matches:
                    metadata = match.metadata
                    
                    # Extract content based on available fields
                    content = ""
                    if 'content_fr' in metadata and metadata['content_fr']:
                        content = metadata['content_fr']
                    elif 'content_ar' in metadata and metadata['content_ar']:
                        content = metadata['content_ar']
                    elif 'summary' in metadata:
                        content = metadata['summary']
                    else:
                        continue  # Skip if no content found
                    
                    # Create document-like object
                    doc = type('Document', (), {
                        'page_content': content,
                        'metadata': metadata
                    })()
                    
                    results.append((doc, match.score))
                    
            except Exception as e:
                st.error(f"Erreur lors de la recherche: {e}")
                
            return results
        
        def similarity_search(self, query: str, k: int = 4, filter: Optional[dict] = None, **kwargs):
            """Override similarity_search to use our custom method"""
            docs_and_scores = self.similarity_search_with_score(query, k=k, filter=filter, **kwargs)
            return [doc for doc, score in docs_and_scores]
    
    vector_store = TunisianLegalVectorStore(index=index, embedding=embeddings, text_key="content")
    
    # LLM clients
    llm_chat = ChatOpenAI(api_key=OPENAI_API_KEY, model=CHAT_MODEL, temperature=0.7)
    llm_analysis = ChatOpenAI(api_key=OPENAI_API_KEY, model=ANALYSIS_MODEL, temperature=0.3)
    llm_rerank = ChatOpenAI(api_key=OPENAI_API_KEY, model=RERANK_MODEL, temperature=0)
    
    return {
        "vector_store": vector_store,
        "llm_chat": llm_chat,
        "llm_analysis": llm_analysis,
        "llm_rerank": llm_rerank,
        "index": index
    }

# Initialize connections
connections = initialize_connections()
vector_store = connections["vector_store"]
llm_chat = connections["llm_chat"]
llm_analysis = connections["llm_analysis"]
llm_rerank = connections["llm_rerank"]

# --- Enhanced Data Classes ---
@dataclass
class LegalDocument:
    id: str
    title: str
    article_number: int
    content_fr: str
    content_ar: str
    legal_code: str
    summary: str
    tags: List[str]
    status: str
    relevance_score: float = 0.0
    
@dataclass
class ConversationContext:
    user_question: str
    detected_language: str
    legal_domain: str
    complexity_level: str
    follow_up_questions: List[str]

# --- Human-like Legal Expert Class ---
class MaitreKhalil:
    def __init__(self):
        self.name = "MaÃ®tre Khalil Ben Ahmed"
        self.specialties = [
            "Droit commercial tunisien",
            "Droit civil et obligations",
            "Droit pÃ©nal des affaires",
            "ComptabilitÃ© publique",
            "ProcÃ©dures juridiques"
        ]
        self.vector_store = vector_store
        self.llm_chat = llm_chat
        self.llm_analysis = llm_analysis
        self.llm_rerank = llm_rerank
        
    def _detect_language_and_context(self, query: str) -> ConversationContext:
        """Analyze the query to understand context and user needs"""
        
        # Simple language detection
        arabic_chars = len(re.findall(r'[\u0600-\u06FF]', query))
        total_chars = len(query.replace(' ', ''))
        detected_language = "ar" if arabic_chars > total_chars * 0.3 else "fr"
        
        # Detect legal domain based on keywords
        domain_keywords = {
            "commercial": ["commerce", "entreprise", "sociÃ©tÃ©", "contrat commercial", "ØªØ¬Ø§Ø±Ø©", "Ø´Ø±ÙƒØ©"],
            "civil": ["mariage", "divorce", "succession", "propriÃ©tÃ©", "Ø²ÙˆØ§Ø¬", "Ø·Ù„Ø§Ù‚", "Ù…ÙŠØ±Ø§Ø«"],
            "penal": ["crime", "dÃ©lit", "sanction", "prison", "Ø¬Ø±ÙŠÙ…Ø©", "Ø¹Ù‚ÙˆØ¨Ø©"],
            "public": ["administration", "finances publiques", "comptabilitÃ©", "Ø¥Ø¯Ø§Ø±Ø©", "Ù…Ø§Ù„ÙŠØ© Ø¹Ø§Ù…Ø©"],
            "procedure": ["procÃ©dure", "tribunal", "recours", "Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª", "Ù…Ø­ÙƒÙ…Ø©"]
        }
        
        legal_domain = "general"
        for domain, keywords in domain_keywords.items():
            if any(keyword.lower() in query.lower() for keyword in keywords):
                legal_domain = domain
                break
        
        # Assess complexity
        complexity_indicators = ["exception", "recours", "cassation", "constitutionnel", "Ø§Ø³ØªØ«Ù†Ø§Ø¡", "Ø·Ø¹Ù†"]
        complexity_level = "complex" if any(ind.lower() in query.lower() for ind in complexity_indicators) else "standard"
        
        return ConversationContext(
            user_question=query,
            detected_language=detected_language,
            legal_domain=legal_domain,
            complexity_level=complexity_level,
            follow_up_questions=[]
        )
    
    def _search_legal_documents(self, query: str, legal_code: Optional[str] = None, top_k: int = 15) -> List[LegalDocument]:
        """Search for relevant legal documents"""
        
        try:
            # Build filter
            filter_dict = {}
            if legal_code and legal_code != "all":
                filter_dict["legal_code"] = {"$eq": legal_code}
            
            # Search with our custom vector store
            docs_with_scores = vector_store.similarity_search_with_score(
                query, 
                k=top_k, 
                filter=filter_dict
            )
            
            legal_docs = []
            for doc, score in docs_with_scores:
                metadata = doc.metadata
                
                legal_doc = LegalDocument(
                    id=metadata.get("id", "unknown"),
                    title=metadata.get("title", "Document sans titre"),
                    article_number=metadata.get("article_index", 0),
                    content_fr=metadata.get("content_fr", ""),
                    content_ar=metadata.get("content_ar", ""),
                    legal_code=metadata.get("legal_code", ""),
                    summary=metadata.get("summary", ""),
                    tags=metadata.get("tags", []),
                    status=metadata.get("status", ""),
                    relevance_score=float(score)
                )
                legal_docs.append(legal_doc)
            
            return legal_docs
            
        except Exception as e:
            st.error(f"Erreur lors de la recherche: {e}")
            return []
    
    def _rerank_documents(self, context: ConversationContext, documents: List[LegalDocument]) -> List[LegalDocument]:
        """Intelligently rerank documents based on context"""
        
        if not documents:
            return []
        
        # Prepare documents for ranking
        docs_for_ranking = []
        for doc in documents:
            content = doc.content_fr if context.detected_language == "fr" else doc.content_ar
            if not content:  # Fallback to the other language
                content = doc.content_ar if context.detected_language == "fr" else doc.content_fr
            
            docs_for_ranking.append({
                "id": doc.id,
                "title": doc.title,
                "article_number": doc.article_number,
                "legal_code": doc.legal_code,
                "content": content[:800],  # Truncate for ranking
                "summary": doc.summary,
                "tags": doc.tags
            })
        
        rerank_prompt = f"""En tant qu'expert juridique tunisien, Ã©valuez la pertinence de chaque document pour cette question:

Question: {context.user_question}
Domaine juridique dÃ©tectÃ©: {context.legal_domain}
Niveau de complexitÃ©: {context.complexity_level}

Documents Ã  Ã©valuer:
{json.dumps(docs_for_ranking, ensure_ascii=False, indent=2)}

Donnez un score de pertinence (0-100) pour chaque document. ConsidÃ©rez:
- Pertinence directe au problÃ¨me juridique
- ApplicabilitÃ© en droit tunisien
- Niveau de dÃ©tail appropriÃ©

RÃ©pondez uniquement en JSON:
{{"rankings": [{{"id": "...", "score": 0-100, "rationale": "..."}}]}}"""

        try:
            response = self.llm_rerank.invoke([{"role": "user", "content": rerank_prompt}])
            rankings_data = json.loads(response.content.strip())
            
            # Apply new scores
            id_to_score = {r["id"]: r["score"] for r in rankings_data.get("rankings", [])}
            for doc in documents:
                doc.relevance_score = id_to_score.get(doc.id, doc.relevance_score)
            
            # Sort by new relevance score
            return sorted(documents, key=lambda x: x.relevance_score, reverse=True)[:5]
            
        except Exception as e:
            st.warning(f"ProblÃ¨me avec le re-classement: {e}")
            return documents[:5]
    
    def _generate_human_response(self, context: ConversationContext, relevant_docs: List[LegalDocument]) -> str:
        """Generate a natural, human-like response"""
        
        if not relevant_docs:
            return self._generate_no_results_response(context)
        
        # Prepare legal context
        legal_context = []
        for doc in relevant_docs:
            content = doc.content_fr if context.detected_language == "fr" else doc.content_ar
            if not content:
                content = doc.content_ar if context.detected_language == "fr" else doc.content_fr
            
            legal_context.append({
                "article": doc.article_number,
                "title": doc.title,
                "code": doc.legal_code,
                "content": content,
                "summary": doc.summary,
                "status": doc.status,
                "relevance": doc.relevance_score
            })
        
        # Create human-like persona prompt
        persona_prompt = f"""Vous Ãªtes MaÃ®tre Khalil Ben Ahmed, un avocat tunisien expÃ©rimentÃ© avec 20 ans d'expÃ©rience.

VOTRE PERSONNALITÃ‰:
- Chaleureux et accessible, mais professionnel
- Vous expliquez le droit de maniÃ¨re claire et pÃ©dagogique
- Vous utilisez des exemples concrets
- Vous Ãªtes prudent et mentionnez quand consulter un avocat
- Vous maÃ®trisez parfaitement le franÃ§ais et l'arabe
- Vous avez une connaissance approfondie du droit tunisien

STYLE DE COMMUNICATION:
- Commencez par une salutation personnelle
- Structurez votre rÃ©ponse clairement
- Utilisez "En droit tunisien..." ou "Selon la lÃ©gislation..."
- Terminez par des conseils pratiques
- Soyez empathique aux prÃ©occupations du client

QUESTION DU CLIENT: {context.user_question}

CONTEXTE JURIDIQUE PERTINENT:
{json.dumps(legal_context, ensure_ascii=False, indent=2)}

RÃ©pondez comme un vrai avocat tunisien le ferait lors d'une consultation. Soyez naturel, professionnel et rassurant."""

        try:
            response = self.llm_chat.invoke([{"role": "user", "content": persona_prompt}])
            base_response = response.content.strip()
            
            # Add legal references in a natural way
            if relevant_docs:
                base_response += "\n\nğŸ“‹ **RÃ©fÃ©rences juridiques consultÃ©es:**\n"
                for i, doc in enumerate(relevant_docs[:3], 1):
                    base_response += f"{i}. Article {doc.article_number} - {doc.title} ({doc.legal_code})\n"
                    if doc.status:
                        base_response += f"   *{doc.status}*\n"
            
            return base_response
            
        except Exception as e:
            return f"Je suis dÃ©solÃ©, j'ai rencontrÃ© un problÃ¨me technique. Pouvez-vous reformuler votre question ? (Erreur: {e})"
    
    def _generate_no_results_response(self, context: ConversationContext) -> str:
        """Generate a helpful response when no relevant documents are found"""
        
        responses = [
            f"Je comprends votre question sur {context.legal_domain}, mais je n'ai pas trouvÃ© de textes juridiques spÃ©cifiques dans ma base de donnÃ©es actuelle.",
            "Permettez-moi de vous orienter diffÃ©remment. Pouvez-vous me donner plus de dÃ©tails sur votre situation ?",
            "En attendant, je vous recommande de consulter directement un confrÃ¨re spÃ©cialisÃ© pour une analyse personnalisÃ©e."
        ]
        
        if context.legal_domain != "general":
            responses.append(f"Pour les questions de {context.legal_domain}, il serait peut-Ãªtre utile de consulter directement le code concernÃ©.")
        
        return "\n\n".join(responses)
    
    def respond_to_question(self, user_input: str, legal_code_filter: Optional[str] = None) -> Tuple[str, Dict]:
        """Main method to process user question and generate response"""
        
        # Analyze context
        context = self._detect_language_and_context(user_input)
        
        # Search for relevant documents
        documents = self._search_legal_documents(
            user_input, 
            legal_code=legal_code_filter,
            top_k=15
        )
        
        # Rerank based on context
        relevant_docs = self._rerank_documents(context, documents)
        
        # Generate human-like response
        response = self._generate_human_response(context, relevant_docs)
        
        # Prepare metadata for UI
        metadata = {
            "detected_language": context.detected_language,
            "legal_domain": context.legal_domain,
            "documents_found": len(documents),
            "documents_used": len(relevant_docs),
            "complexity": context.complexity_level
        }
        
        return response, metadata

# --- Streamlit Interface ---
def main():
    # Header with expert introduction
    st.markdown("""
    <div style='text-align: center; padding: 2rem 0;'>
        <h1>ğŸ›ï¸ MaÃ®tre Khalil Ben Ahmed</h1>
        <h3 style='color: #666; font-weight: normal;'>Avocat & Expert en Droit Tunisien</h3>
        <p style='font-style: italic; color: #888;'>SpÃ©cialisÃ© en droit commercial, civil et comptabilitÃ© publique</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar with expert profile
    with st.sidebar:
        st.markdown("""
        ### ğŸ‘¨â€âš–ï¸ Profil de l'Expert
        
        **MaÃ®tre Khalil Ben Ahmed**
        - ğŸ“ 20+ ans d'expÃ©rience
        - ğŸ›ï¸ Droit tunisien
        - ğŸ“š SpÃ©cialitÃ©s multiples
        - ğŸŒ Bilingue FR/AR
        
        ---
        """)
        
        # Legal code filter
        st.subheader("ğŸ” Filtrer par domaine")
        legal_codes = {
            "Tous les domaines": None,
            "ğŸ“Š ComptabilitÃ© publique": "code-comptabilite-publique",
            "ğŸ¢ Droit commercial": "code-commerce",
            "ğŸ‘¥ Droit civil": "code-civil",
            "âš–ï¸ Droit pÃ©nal": "code-penal",
            "ğŸ’¼ Droit du travail": "code-travail",
            "ğŸ“‹ ProcÃ©dure civile": "code-procedure-civile"
        }
        
        selected_code_display = st.selectbox(
            "Domaine juridique",
            list(legal_codes.keys()),
            help="Concentrer la recherche sur un domaine spÃ©cifique"
        )
        selected_code = legal_codes[selected_code_display]
        
        # Expert availability status
        st.markdown("""
        ---
        ### ğŸ“Š Statut
        ğŸŸ¢ **En ligne** - RÃ©ponse immÃ©diate  
        ğŸ“– Base juridique Ã  jour  
        ğŸ”’ Consultations confidentielles
        """)
        
        # Quick tips
        with st.expander("ğŸ’¡ Conseils pour de meilleures rÃ©ponses"):
            st.markdown("""
            - Soyez spÃ©cifique dans vos questions
            - Mentionnez le contexte (personnel/entreprise)
            - PrÃ©cisez si c'est urgent
            - N'hÃ©sitez pas Ã  demander des clarifications
            """)
    
    # Initialize chat
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # Add welcome message
        welcome_msg = """Bonjour ! Je suis MaÃ®tre Khalil Ben Ahmed, avocat spÃ©cialisÃ© en droit tunisien.

Je suis lÃ  pour vous aider avec vos questions juridiques, que ce soit en droit commercial, civil, pÃ©nal, ou comptabilitÃ© publique. 

N'hÃ©sitez pas Ã  me poser votre question en franÃ§ais ou en arabe. Je vous donnerai une rÃ©ponse claire avec les rÃ©fÃ©rences juridiques appropriÃ©es.

Comment puis-je vous aider aujourd'hui ? ğŸ˜Š"""
        
        st.session_state.messages.append({
            "role": "assistant", 
            "content": welcome_msg,
            "metadata": {}
        })
    
    if "expert" not in st.session_state:
        st.session_state.expert = MaitreKhalil()
    
    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant":
                st.markdown(f'<div class="expert-name">ğŸ‘¨â€âš–ï¸ MaÃ®tre Khalil</div>', unsafe_allow_html=True)
            
            st.markdown(message["content"])
            
            # Show metadata for assistant messages (except welcome)
            if (message["role"] == "assistant" and 
                message.get("metadata") and 
                len(message["metadata"]) > 0):
                
                meta = message["metadata"]
                with st.expander("ğŸ“Š DÃ©tails de l'analyse", expanded=False):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ğŸŒ Langue dÃ©tectÃ©e", meta.get("detected_language", "fr").upper())
                    with col2:
                        st.metric("âš–ï¸ Domaine", meta.get("legal_domain", "general"))
                    with col3:
                        st.metric("ğŸ“„ Documents analysÃ©s", f"{meta.get('documents_used', 0)}/{meta.get('documents_found', 0)}")
    
    # Chat input
    if prompt := st.chat_input("Tapez votre question juridique..."):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt, "metadata": {}})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Generate expert response
        with st.chat_message("assistant"):
            st.markdown(f'<div class="expert-name">ğŸ‘¨â€âš–ï¸ MaÃ®tre Khalil</div>', unsafe_allow_html=True)
            
            # Show thinking indicator
            thinking_placeholder = st.empty()
            thinking_placeholder.markdown('<div class="thinking-indicator">ğŸ¤” Analyse de votre question et recherche dans la jurisprudence...</div>', unsafe_allow_html=True)
            
            try:
                # Get response from expert
                response, metadata = st.session_state.expert.respond_to_question(
                    prompt, 
                    legal_code_filter=selected_code
                )
                
                # Clear thinking indicator and show response
                thinking_placeholder.empty()
                st.markdown(response)
                
                # Store the response
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "metadata": metadata
                })
                
                # Show analysis details
                if metadata:
                    with st.expander("ğŸ“Š DÃ©tails de l'analyse", expanded=False):
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ğŸŒ Langue dÃ©tectÃ©e", metadata.get("detected_language", "fr").upper())
                        with col2:
                            st.metric("âš–ï¸ Domaine", metadata.get("legal_domain", "general"))
                        with col3:
                            st.metric("ğŸ“„ Documents analysÃ©s", f"{metadata.get('documents_used', 0)}/{metadata.get('documents_found', 0)}")
                
            except Exception as e:
                thinking_placeholder.empty()
                error_msg = f"Je suis dÃ©solÃ©, j'ai rencontrÃ© un problÃ¨me technique. Pouvez-vous rÃ©essayer ? ğŸ”§\n\nDÃ©tails: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": error_msg,
                    "metadata": {}
                })
    
    # Footer
    st.markdown("---")
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        st.markdown("""
        <div style='font-size: 0.8em; color: #666;'>
        âš ï¸ <strong>Avertissement:</strong> Ces rÃ©ponses sont Ã  titre informatif uniquement. 
        Pour des conseils juridiques personnalisÃ©s, consultez un avocat.
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        if st.button("ğŸ”„ Nouvelle consultation"):
            st.session_state.messages = []
            st.rerun()
    
    with col3:
        if st.button("ğŸ“ Contact direct"):
            st.info("ğŸ“§ khalil.ahmed@avocat.tn\nğŸ“± +216 XX XXX XXX")

if __name__ == "__main__":
    main()